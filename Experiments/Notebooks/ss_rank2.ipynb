{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "# import sage\n",
    "# from scipy.stats import rankdata\n",
    "from scipy.stats import ttest_ind, t\n",
    "import sys\n",
    "from helper import *\n",
    "from shapley_sampling1 import *\n",
    "# from os.path import join\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import TensorDataset, DataLoader, WeightedRandomSampler\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.random.seed(1)\n",
    "# data = pd.read_csv(\"Data/brca_small.csv\")\n",
    "# X = data.values[:, :-1][:,:20]\n",
    "# Y = data.values[:, -1]\n",
    "# Y = (Y==2).astype(int) # Formulate as binary classification problem\n",
    "\n",
    "# # Split data\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=100, random_state=0)\n",
    "\n",
    "# # Normalize\n",
    "# mean = X_train.mean(axis=0)\n",
    "# std = X_train.std(axis=0)\n",
    "# X_train = (X_train - mean) / std\n",
    "# X_test = (X_test - mean) / std\n",
    "# d = X_train.shape[1]\n",
    "# mapping_dict = None\n",
    "\n",
    "# # Compute mean and covariance of training data\n",
    "# feature_means = np.mean(X_train, axis=0)\n",
    "# cov_mat = correct_cov(np.cov(X_train, rowvar=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = sage.datasets.credit()\n",
    "# df.to_csv(\"Data/credit.csv\")\n",
    "df = pd.read_csv(\"Data/credit.csv\", index_col=0)\n",
    "\n",
    "# Property, other installment, housing, job, status of checking act, credit history, purpose, savings, employment since, marital status, old debtors\n",
    "n = df.shape[0]\n",
    "X_df = df.drop([\"Good Customer\"], axis=1)\n",
    "y = df[\"Good Customer\"]\n",
    "\n",
    "categorical_columns = [\n",
    "    'Checking Status', 'Credit History', 'Purpose', #'Credit Amount', # It's listed but has 923 unique values\n",
    "    'Savings Account/Bonds', 'Employment Since', 'Personal Status',\n",
    "    'Debtors/Guarantors', 'Property Type', 'Other Installment Plans',\n",
    "    'Housing Ownership', 'Job', #'Telephone', 'Foreign Worker' # These are just binary\n",
    "]\n",
    "X_binarized = pd.get_dummies(X_df, columns=categorical_columns)\n",
    "\n",
    "mapping_dict = {}\n",
    "for i, col in enumerate(X_df.columns):\n",
    "    bin_cols = []\n",
    "    for j, bin_col in enumerate(X_binarized.columns):\n",
    "        if bin_col.startswith(col):\n",
    "            bin_cols.append(j)\n",
    "    mapping_dict[i] = bin_cols\n",
    "\n",
    "np.random.seed(1)\n",
    "X_norm = (X_binarized-X_binarized.min())/(X_binarized.max()-X_binarized.min())\n",
    "n_train = round(n*0.8)\n",
    "train_idx = np.random.choice(n, n_train, replace=False)\n",
    "X_train, y_train = X_norm.iloc[train_idx].to_numpy(), y.iloc[train_idx].to_numpy()\n",
    "test_idx = np.setdiff1d(np.arange(n),train_idx)\n",
    "X_test, y_test = X_norm.iloc[test_idx].to_numpy(), y.iloc[test_idx].to_numpy()\n",
    "d = X_df.shape[1]\n",
    "d_bin = X_train.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bank dataset\n",
    "# import sage\n",
    "# from sklearn.model_selection import train_test_split\n",
    "\n",
    "# df = sage.datasets.bank()\n",
    "# df.Default = df.Default.map({'no': 0, 'yes': 1})\n",
    "# df.Housing = df.Housing.map({'no': 0, 'yes': 1})\n",
    "# df.Loan = df.Loan.map({'no': 0, 'yes': 1})\n",
    "# df.columns = df.columns.str.replace(' ', '_')\n",
    "# df_bin = pd.get_dummies(df)\n",
    "\n",
    "# # That's literally it. Note this mapping dict is a little different.\n",
    "# train, test = train_test_split(\n",
    "#     df_bin.values, test_size=int(0.1 * len(df_bin.values)), random_state=123)\n",
    "\n",
    "# suc_idx = df_bin.columns.get_loc(\"Success\")\n",
    "# y_train = train[:, suc_idx].copy().astype(int)\n",
    "# y_test = test[:, suc_idx].copy().astype(int)\n",
    "# X_train = np.delete(train, suc_idx, axis=1).astype(\"float64\")\n",
    "# X_test = np.delete(test, suc_idx, axis=1).astype(\"float64\")\n",
    "\n",
    "# # Get mapping dict\n",
    "# X_df = df_bin.drop([\"Success\"], axis=1)\n",
    "# mapping_dict = {}\n",
    "# for i, col in enumerate(df.columns):\n",
    "#     bin_cols = []\n",
    "#     for j, bin_col in enumerate(X_df.columns):\n",
    "#         if bin_col.startswith(col):\n",
    "#             bin_cols.append(j)\n",
    "#     mapping_dict[i] = bin_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Adult census income dataset\n",
    "# import shap\n",
    "# X, y = shap.datasets.adult()\n",
    "# X_display, y_display = shap.datasets.adult(display=True)\n",
    "# X_binarized = pd.get_dummies(X_display)\n",
    "\n",
    "# mapping_dict = {}\n",
    "# for i, col in enumerate(X_display.columns):\n",
    "#     bin_cols = []\n",
    "#     for j, bin_col in enumerate(X_binarized.columns):\n",
    "#         if bin_col.startswith(col):\n",
    "#             bin_cols.append(j)\n",
    "#     mapping_dict[i] = bin_cols\n",
    "\n",
    "# X_norm = (X_binarized-X_binarized.min())/(X_binarized.max()-X_binarized.min())\n",
    "# y_int = y_display.astype(\"int8\")\n",
    "\n",
    "# # Split into training and test sets\n",
    "# np.random.seed(1)\n",
    "# n, d = X_norm.shape\n",
    "# n_train = round(n*0.75)\n",
    "# train_idx = np.random.choice(n, size=n_train, replace=False)\n",
    "# X_train_pd, y_train = X_norm.iloc[train_idx], y_int[train_idx]\n",
    "# X_train = X_train_pd.to_numpy()\n",
    "\n",
    "# test_idx = np.setdiff1d(list(range(n)), train_idx)\n",
    "# X_test_pd, y_test = X_norm.iloc[test_idx], y_int[test_idx]\n",
    "# X_test = X_test_pd.to_numpy()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define neural network, train, and move to numpy\n",
    "- Trains with balanced weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class imbalance: 72%\n",
      "NN 68% accuracy\n"
     ]
    }
   ],
   "source": [
    "class TwoLayerNet(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(TwoLayerNet, self).__init__()\n",
    "        self.linear1 = nn.Linear(input_size, hidden_size)\n",
    "        self.tanh = nn.Tanh()\n",
    "        self.linear2 = nn.Linear(hidden_size, output_size)\n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.linear1(x)\n",
    "        out = self.tanh(out)\n",
    "        out = self.linear2(out)\n",
    "        out = self.softmax(out)\n",
    "        return out\n",
    "\n",
    "# Convert the input and label data to PyTorch tensors\n",
    "inputs = torch.tensor(X_train, dtype=torch.float32)\n",
    "labels = torch.tensor(y_train, dtype=torch.long)\n",
    "\n",
    "# Compute the class weights\n",
    "class_counts = torch.bincount(labels)\n",
    "num_samples = len(labels)\n",
    "class_weights = 1.0 / class_counts.float()\n",
    "sample_weights = class_weights[labels]\n",
    "\n",
    "# Create a sampler with balanced weights\n",
    "sampler = WeightedRandomSampler(weights=sample_weights, num_samples=num_samples, replacement=True)\n",
    "\n",
    "# Create a DataLoader with the sampler\n",
    "dataset = TensorDataset(inputs, labels)\n",
    "dataloader = DataLoader(dataset, batch_size=32, sampler=sampler)\n",
    "# dataloader = DataLoader(dataset, batch_size=32)\n",
    "\n",
    "torch.manual_seed(0)\n",
    "\n",
    "# Create an instance\n",
    "net = TwoLayerNet(input_size=X_train.shape[1], hidden_size=50, output_size=2)\n",
    "# Define the loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(net.parameters(), lr=0.001)#.01\n",
    "\n",
    "# Iterate over the training data in batches\n",
    "num_epochs = 20\n",
    "\n",
    "# Train the network for the specified number of epochs\n",
    "for epoch in range(num_epochs):\n",
    "    for inputs, labels in dataloader:\n",
    "        optimizer.zero_grad()\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    # print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {loss.item():.4f}\")\n",
    "\n",
    "def neural_net(x):\n",
    "    output = net(x)[0,1] if x.shape[0]==1 else net(x)[:,1]\n",
    "    return output\n",
    "\n",
    "def compute_hessian(x):\n",
    "    if not torch.is_tensor(x):\n",
    "        x = torch.tensor(x, dtype=torch.float32)\n",
    "    dim = x.shape[1]\n",
    "    hessian = torch.autograd.functional.hessian(neural_net, x)\n",
    "    hessian = hessian.reshape((dim,dim)).detach().numpy()\n",
    "    return hessian\n",
    "\n",
    "def model(x):\n",
    "    if not torch.is_tensor(x):\n",
    "        x = torch.tensor(x, dtype=torch.float32)\n",
    "    return neural_net(x).detach().numpy()\n",
    "\n",
    "print(\"Class imbalance: {}%\".format(round(100*(max(np.mean(y_test), 1-np.mean(y_test))))))\n",
    "Y_preds = (model(X_test) > 0.5).astype(\"int\")\n",
    "print(\"NN {}% accuracy\".format(round(np.mean(Y_preds == y_test)*100)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run helper\n",
    "# Compute mean and covariance of training data\n",
    "feature_means = np.mean(X_train, axis=0)\n",
    "cov_mat = correct_cov(np.cov(X_train, rowvar=False))\n",
    "\n",
    "# Select point and compute its gradient and hessian\n",
    "xloc = X_test[0:1]\n",
    "xloc_torch = torch.tensor(xloc, dtype=torch.float32).requires_grad_(True)\n",
    "y_pred = net(xloc_torch)[0,1]\n",
    "y_pred.backward()\n",
    "gradient = xloc_torch.grad.detach().numpy().reshape((xloc.shape[1], 1))\n",
    "hessian = compute_hessian(xloc)\n",
    "\n",
    "# Obtain true SHAP values and verify their feasibility\n",
    "true_shap_vals = compute_shap_vals_quadratic(xloc, gradient, hessian, feature_means, cov_mat, mapping_dict=mapping_dict)\n",
    "\n",
    "y_pred = y_pred.detach().numpy()\n",
    "def approx(input):\n",
    "    return f_second_order_approx(y_pred,input,xloc,gradient,hessian)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Shapley Sampling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Algo 1a: Non-adaptive. Keep running for all features until convergence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[170], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m# np.random.seed(1)\u001b[39;00m\n\u001b[1;32m      3\u001b[0m K \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m3\u001b[39m\n\u001b[0;32m----> 4\u001b[0m shap_vals, diffs_all_feats \u001b[38;5;241m=\u001b[39m \u001b[43mshapley_sampling_basic\u001b[49m\u001b[43m(\u001b[49m\u001b[43mapprox\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mxloc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mK\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m                                                    \u001b[49m\u001b[43mn_perms_btwn_tests\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_init\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m50\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_samples_per_perm\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m                                                    \u001b[49m\u001b[43malpha\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmapping_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmapping_dict\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28mprint\u001b[39m(diffs_all_feats\u001b[38;5;241m.\u001b[39mshape)\n",
      "File \u001b[0;32m~/Desktop/RankSHAP/shapley_sampling.py:144\u001b[0m, in \u001b[0;36mshapley_sampling_basic\u001b[0;34m(model, X, xloc, K, mapping_dict, alpha, n_perms_btwn_tests, n_samples_per_perm, K_thru_rest, n_init)\u001b[0m\n\u001b[1;32m    <a href='file:///Users/jeremygoldwasser/Desktop/RankSHAP/shapley_sampling.py?line=141'>142</a>\u001b[0m diffs_all_feats \u001b[39m=\u001b[39m compute_diffs_all_feats(model, X, xloc, n_first, mapping_dict\u001b[39m=\u001b[39mmapping_dict, n_samples_per_perm\u001b[39m=\u001b[39mn_samples_per_perm)\n\u001b[1;32m    <a href='file:///Users/jeremygoldwasser/Desktop/RankSHAP/shapley_sampling.py?line=142'>143</a>\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mnot\u001b[39;00m do_all_tests_pass(diffs_all_feats, K, alpha\u001b[39m=\u001b[39malpha, K_thru_rest\u001b[39m=\u001b[39mK_thru_rest):\n\u001b[0;32m--> <a href='file:///Users/jeremygoldwasser/Desktop/RankSHAP/shapley_sampling.py?line=143'>144</a>\u001b[0m     diffs_all_feats_new \u001b[39m=\u001b[39m compute_diffs_all_feats(model, X, xloc, n_perms_btwn_tests, mapping_dict\u001b[39m=\u001b[39;49mmapping_dict, n_samples_per_perm\u001b[39m=\u001b[39;49mn_samples_per_perm)\n\u001b[1;32m    <a href='file:///Users/jeremygoldwasser/Desktop/RankSHAP/shapley_sampling.py?line=144'>145</a>\u001b[0m     diffs_all_feats \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mconcatenate((diffs_all_feats, np\u001b[39m.\u001b[39marray(diffs_all_feats_new)), axis\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[1;32m    <a href='file:///Users/jeremygoldwasser/Desktop/RankSHAP/shapley_sampling.py?line=145'>146</a>\u001b[0m shap_vals \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mmean(diffs_all_feats, axis\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\n",
      "File \u001b[0;32m~/Desktop/RankSHAP/shapley_sampling.py:127\u001b[0m, in \u001b[0;36mcompute_diffs_all_feats\u001b[0;34m(model, X, xloc, M, mapping_dict, n_samples_per_perm, as_np)\u001b[0m\n\u001b[1;32m    <a href='file:///Users/jeremygoldwasser/Desktop/RankSHAP/shapley_sampling.py?line=123'>124</a>\u001b[0m w_vals \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mreshape(w_vals, [M\u001b[39m*\u001b[39mn_samples_per_perm, xloc\u001b[39m.\u001b[39mshape[\u001b[39m1\u001b[39m]])\n\u001b[1;32m    <a href='file:///Users/jeremygoldwasser/Desktop/RankSHAP/shapley_sampling.py?line=124'>125</a>\u001b[0m wj_vals \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mreshape(wj_vals, [M\u001b[39m*\u001b[39mn_samples_per_perm, xloc\u001b[39m.\u001b[39mshape[\u001b[39m1\u001b[39m]])\n\u001b[0;32m--> <a href='file:///Users/jeremygoldwasser/Desktop/RankSHAP/shapley_sampling.py?line=126'>127</a>\u001b[0m diffs_all \u001b[39m=\u001b[39m model(wj_vals) \u001b[39m-\u001b[39m model(w_vals)\n\u001b[1;32m    <a href='file:///Users/jeremygoldwasser/Desktop/RankSHAP/shapley_sampling.py?line=127'>128</a>\u001b[0m diffs_avg \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mmean(np\u001b[39m.\u001b[39mreshape(diffs_all,[M,n_samples_per_perm]),axis\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m) \u001b[39m# length M\u001b[39;00m\n\u001b[1;32m    <a href='file:///Users/jeremygoldwasser/Desktop/RankSHAP/shapley_sampling.py?line=128'>129</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m as_np: diffs_avg \u001b[39m=\u001b[39m diffs_avg\u001b[39m.\u001b[39mtolist()\n",
      "Cell \u001b[0;32mIn[169], line 19\u001b[0m, in \u001b[0;36mapprox\u001b[0;34m(input)\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapprox\u001b[39m(\u001b[38;5;28minput\u001b[39m):\n\u001b[0;32m---> 19\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mf_second_order_approx\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43mxloc\u001b[49m\u001b[43m,\u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43mhessian\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/RankSHAP/helper.py:51\u001b[0m, in \u001b[0;36mf_second_order_approx\u001b[0;34m(y_pred, xnew, xloc, gradient, hessian)\u001b[0m\n\u001b[1;32m     <a href='file:///Users/jeremygoldwasser/Desktop/RankSHAP/helper.py?line=48'>49</a>\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(n):\n\u001b[1;32m     <a href='file:///Users/jeremygoldwasser/Desktop/RankSHAP/helper.py?line=49'>50</a>\u001b[0m     deltaX_i \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39marray(xnew[i,:] \u001b[39m-\u001b[39m xloc)\u001b[39m.\u001b[39mreshape((d, \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m))\n\u001b[0;32m---> <a href='file:///Users/jeremygoldwasser/Desktop/RankSHAP/helper.py?line=50'>51</a>\u001b[0m     second_order_approx[i] \u001b[39m=\u001b[39m y_pred \u001b[39m+\u001b[39m np\u001b[39m.\u001b[39mdot(deltaX_i\u001b[39m.\u001b[39;49mT, gradient) \u001b[39m+\u001b[39m \u001b[39m0.5\u001b[39m\u001b[39m*\u001b[39mnp\u001b[39m.\u001b[39mdot(np\u001b[39m.\u001b[39mdot(deltaX_i\u001b[39m.\u001b[39mT, hessian), deltaX_i)\n\u001b[1;32m     <a href='file:///Users/jeremygoldwasser/Desktop/RankSHAP/helper.py?line=51'>52</a>\u001b[0m \u001b[39mreturn\u001b[39;00m second_order_approx\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "%run shapley_sampling1\n",
    "# np.random.seed(1)\n",
    "K = 3\n",
    "shap_vals, diffs_all_feats = shapley_sampling_basic(approx, X_train, xloc, K, \n",
    "                                                    n_perms_btwn_tests=10, n_init=50, n_samples_per_perm=2,\n",
    "                                                    alpha=0.2, mapping_dict=mapping_dict)\n",
    "print(diffs_all_feats.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Algo 1b: Adaptive. Keep running on features that fail pairwise test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Number of times computing $v_x(S \\cup j) - v_x(S)$, with neural net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50520\n",
      "5400\n",
      "[ 2 11  0  8  1 16  7 13  6  3  4 19 18 17  5 12 10  9 15 14]\n",
      "[ 2 11  8  1  0 16  6  7  4  5 13 19  3 18 17 12 10  9 14 15]\n",
      "[ 2 11  0  8 16  1 13  7  3  5  4 19  6 17 18 12  9 14 10 15]\n"
     ]
    }
   ],
   "source": [
    "# np.random.seed(1)\n",
    "shap_vals2, diffs_all_feats2 = shapley_sampling_adaptive(approx, X_train, xloc, K, \n",
    "                                        mapping_dict=mapping_dict, alpha=0.2, \n",
    "                                        n_perms_btwn_tests=10, n_init=50, n_samples_per_perm=2,\n",
    "                                        K_thru_rest=False)\n",
    "print(sum([len(diffs_all_feats2[j]) for j in range(len(diffs_all_feats2))]))\n",
    "print(np.product(diffs_all_feats.shape))\n",
    "\n",
    "print(get_ordering(true_shap_vals))\n",
    "print(get_ordering(shap_vals))\n",
    "print(get_ordering(shap_vals2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3060394\n",
      "0.9601558484137058\n",
      "1.0561681243313785\n",
      "0.9215477463980719\n"
     ]
    }
   ],
   "source": [
    "print(model(xloc) - np.mean(model(X_train)))\n",
    "print(np.sum(true_shap_vals))\n",
    "print(np.sum(shap_vals))\n",
    "print(np.sum(shap_vals2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Speed-up on model SHAP values\n",
    "\n",
    "Census\n",
    "- K=1: No change\n",
    "- K=2: 2x\n",
    "- K=3, 5: 2.5x\n",
    "- K=7: 3.5x\n",
    "\n",
    "BRCA (slow)\n",
    "- K=1: 5x\n",
    "- K=2: ~10x (?)\n",
    "\n",
    "Credit\n",
    "- K=1: 20x\n",
    "- K=2: 10x\n",
    "- K=3: 20x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.33\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[229], line 5\u001b[0m\n\u001b[1;32m      2\u001b[0m K \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m2\u001b[39m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m20\u001b[39m):\n\u001b[1;32m      4\u001b[0m     \u001b[38;5;66;03m# print(i)\u001b[39;00m\n\u001b[0;32m----> 5\u001b[0m     shap_vals, diffs_all_feats \u001b[38;5;241m=\u001b[39m \u001b[43mshapley_sampling_basic\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mxloc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mK\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m                                                    \u001b[49m\u001b[43mn_perms_btwn_tests\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_init\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m50\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_samples_per_perm\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m                                                    \u001b[49m\u001b[43malpha\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmapping_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmapping_dict\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      8\u001b[0m     shap_vals2, diffs_all_feats2 \u001b[38;5;241m=\u001b[39m shapley_sampling_adaptive(model, X_train, xloc, K, \n\u001b[1;32m      9\u001b[0m                                         mapping_dict\u001b[38;5;241m=\u001b[39mmapping_dict, alpha\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.2\u001b[39m, \n\u001b[1;32m     10\u001b[0m                                         n_perms_btwn_tests\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m, n_init\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m30\u001b[39m, n_samples_per_perm\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m)\n\u001b[1;32m     11\u001b[0m     cts_nonadaptive\u001b[38;5;241m.\u001b[39mappend(np\u001b[38;5;241m.\u001b[39mproduct(diffs_all_feats\u001b[38;5;241m.\u001b[39mshape))\n",
      "File \u001b[0;32m~/Desktop/RankSHAP/shapley_sampling.py:144\u001b[0m, in \u001b[0;36mshapley_sampling_basic\u001b[0;34m(model, X, xloc, K, mapping_dict, alpha, n_perms_btwn_tests, n_samples_per_perm, K_thru_rest, n_init)\u001b[0m\n\u001b[1;32m    <a href='file:///Users/jeremygoldwasser/Desktop/RankSHAP/shapley_sampling.py?line=141'>142</a>\u001b[0m diffs_all_feats \u001b[39m=\u001b[39m compute_diffs_all_feats(model, X, xloc, n_first, mapping_dict\u001b[39m=\u001b[39mmapping_dict, n_samples_per_perm\u001b[39m=\u001b[39mn_samples_per_perm)\n\u001b[1;32m    <a href='file:///Users/jeremygoldwasser/Desktop/RankSHAP/shapley_sampling.py?line=142'>143</a>\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mnot\u001b[39;00m do_all_tests_pass(diffs_all_feats, K, alpha\u001b[39m=\u001b[39malpha, K_thru_rest\u001b[39m=\u001b[39mK_thru_rest):\n\u001b[0;32m--> <a href='file:///Users/jeremygoldwasser/Desktop/RankSHAP/shapley_sampling.py?line=143'>144</a>\u001b[0m     diffs_all_feats_new \u001b[39m=\u001b[39m compute_diffs_all_feats(model, X, xloc, n_perms_btwn_tests, mapping_dict\u001b[39m=\u001b[39;49mmapping_dict, n_samples_per_perm\u001b[39m=\u001b[39;49mn_samples_per_perm)\n\u001b[1;32m    <a href='file:///Users/jeremygoldwasser/Desktop/RankSHAP/shapley_sampling.py?line=144'>145</a>\u001b[0m     diffs_all_feats \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mconcatenate((diffs_all_feats, np\u001b[39m.\u001b[39marray(diffs_all_feats_new)), axis\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[1;32m    <a href='file:///Users/jeremygoldwasser/Desktop/RankSHAP/shapley_sampling.py?line=145'>146</a>\u001b[0m shap_vals \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mmean(diffs_all_feats, axis\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\n",
      "File \u001b[0;32m~/Desktop/RankSHAP/shapley_sampling.py:121\u001b[0m, in \u001b[0;36mcompute_diffs_all_feats\u001b[0;34m(model, X, xloc, M, mapping_dict, n_samples_per_perm, as_np)\u001b[0m\n\u001b[1;32m    <a href='file:///Users/jeremygoldwasser/Desktop/RankSHAP/shapley_sampling.py?line=117'>118</a>\u001b[0m j_idx \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39margwhere(perm\u001b[39m==\u001b[39mj)\u001b[39m.\u001b[39mitem()\n\u001b[1;32m    <a href='file:///Users/jeremygoldwasser/Desktop/RankSHAP/shapley_sampling.py?line=118'>119</a>\u001b[0m S \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39marray(perm[:j_idx])\n\u001b[0;32m--> <a href='file:///Users/jeremygoldwasser/Desktop/RankSHAP/shapley_sampling.py?line=120'>121</a>\u001b[0m tw_vals, twj_vals \u001b[39m=\u001b[39m query_values_marginal(X, xloc, S, j, mapping_dict, n_samples_per_perm)\n\u001b[1;32m    <a href='file:///Users/jeremygoldwasser/Desktop/RankSHAP/shapley_sampling.py?line=121'>122</a>\u001b[0m w_vals\u001b[39m.\u001b[39mappend(tw_vals)\n\u001b[1;32m    <a href='file:///Users/jeremygoldwasser/Desktop/RankSHAP/shapley_sampling.py?line=122'>123</a>\u001b[0m wj_vals\u001b[39m.\u001b[39mappend(twj_vals)\n",
      "File \u001b[0;32m~/Desktop/RankSHAP/shapley_sampling.py:103\u001b[0m, in \u001b[0;36mquery_values_marginal\u001b[0;34m(X, xloc, S, j, mapping_dict, n_samples_per_perm)\u001b[0m\n\u001b[1;32m    <a href='file:///Users/jeremygoldwasser/Desktop/RankSHAP/shapley_sampling.py?line=100'>101</a>\u001b[0m z \u001b[39m=\u001b[39m X[np\u001b[39m.\u001b[39mrandom\u001b[39m.\u001b[39mchoice(n, size\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m),:]\n\u001b[1;32m    <a href='file:///Users/jeremygoldwasser/Desktop/RankSHAP/shapley_sampling.py?line=101'>102</a>\u001b[0m w_x_s, w_x_s_j \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mcopy(xloc), np\u001b[39m.\u001b[39mcopy(xloc)\n\u001b[0;32m--> <a href='file:///Users/jeremygoldwasser/Desktop/RankSHAP/shapley_sampling.py?line=102'>103</a>\u001b[0m w_x_s[\u001b[39m0\u001b[39m][Sc] \u001b[39m=\u001b[39m z[\u001b[39m0\u001b[39;49m][Sc]\n\u001b[1;32m    <a href='file:///Users/jeremygoldwasser/Desktop/RankSHAP/shapley_sampling.py?line=103'>104</a>\u001b[0m w_x_s_j[\u001b[39m0\u001b[39m][Sjc] \u001b[39m=\u001b[39m z[\u001b[39m0\u001b[39m][Sjc]\n\u001b[1;32m    <a href='file:///Users/jeremygoldwasser/Desktop/RankSHAP/shapley_sampling.py?line=105'>106</a>\u001b[0m w_vals\u001b[39m.\u001b[39mappend(w_x_s)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "cts_nonadaptive, cts_adaptive = [], []\n",
    "K = 2\n",
    "for i in range(20):\n",
    "    # print(i)\n",
    "    shap_vals, diffs_all_feats = shapley_sampling_basic(model, X_train, xloc, K, \n",
    "                                                    n_perms_btwn_tests=10, n_init=50, n_samples_per_perm=5,\n",
    "                                                    alpha=0.2, mapping_dict=mapping_dict)\n",
    "    shap_vals2, diffs_all_feats2 = shapley_sampling_adaptive(model, X_train, xloc, K, \n",
    "                                        mapping_dict=mapping_dict, alpha=0.2, \n",
    "                                        n_perms_btwn_tests=10, n_init=30, n_samples_per_perm=5)\n",
    "    cts_nonadaptive.append(np.product(diffs_all_feats.shape))\n",
    "    cts_adaptive.append(sum([len(diffs_all_feats2[j]) for j in range(len(diffs_all_feats2))]))\n",
    "    print(np.round(np.mean(cts_nonadaptive)/np.mean(cts_adaptive), 2))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.85\n"
     ]
    }
   ],
   "source": [
    "print(np.round(np.mean(cts_nonadaptive)/np.mean(cts_adaptive), 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simulation\n",
    "### Quadratic Approximation\n",
    "Not phenomenal. \n",
    "BRCA\n",
    "- K=1: 13%\n",
    "- K=2: 24%\n",
    "\n",
    "Census\n",
    "- K=1: 34%\n",
    "- K=2: 33%\n",
    "\n",
    "Credit\n",
    "- K=2: 38%\n",
    "- K=5: 32%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 0.6\n",
      "10 0.4\n",
      "15 0.47\n",
      "20 0.4\n",
      "25 0.4\n",
      "30 0.47\n",
      "35 0.46\n",
      "40 0.45\n",
      "45 0.44\n",
      "50 0.4\n",
      "55 0.38\n",
      "60 0.37\n",
      "65 0.38\n",
      "70 0.37\n",
      "75 0.37\n",
      "80 0.4\n",
      "85 0.39\n",
      "90 0.38\n",
      "95 0.38\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[249], line 9\u001b[0m\n\u001b[1;32m      6\u001b[0m same_top_K \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m100\u001b[39m):\n\u001b[1;32m      8\u001b[0m     \u001b[38;5;66;03m# print(i)\u001b[39;00m\n\u001b[0;32m----> 9\u001b[0m     shap_vals2, diffs_all_feats2 \u001b[38;5;241m=\u001b[39m \u001b[43mshapley_sampling_adaptive\u001b[49m\u001b[43m(\u001b[49m\u001b[43mapprox\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mxloc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mK\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[43m                                        \u001b[49m\u001b[43mmapping_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmapping_dict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43malpha\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[43m                                        \u001b[49m\u001b[43mn_perms_btwn_tests\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_samples_per_perm\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     12\u001b[0m \u001b[43m                                        \u001b[49m\u001b[43mn_init\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     13\u001b[0m     est_top_K \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39margsort(np\u001b[38;5;241m.\u001b[39mabs(shap_vals2))[::\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m][:K]\n\u001b[1;32m     14\u001b[0m     has_same_top_K \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray_equal(true_top_K, est_top_K)\n",
      "File \u001b[0;32m~/Desktop/RankSHAP/shapley_sampling.py:166\u001b[0m, in \u001b[0;36mshapley_sampling_adaptive\u001b[0;34m(model, X, xloc, K, mapping_dict, alpha, n_perms_btwn_tests, n_samples_per_perm, K_thru_rest, n_init)\u001b[0m\n\u001b[1;32m    <a href='file:///Users/jeremygoldwasser/Desktop/RankSHAP/shapley_sampling.py?line=163'>164</a>\u001b[0m diffs_pair \u001b[39m=\u001b[39m [diffs_all_feats[index_pair[\u001b[39m0\u001b[39m]], diffs_all_feats[index_pair[\u001b[39m1\u001b[39m]]]\n\u001b[1;32m    <a href='file:///Users/jeremygoldwasser/Desktop/RankSHAP/shapley_sampling.py?line=164'>165</a>\u001b[0m \u001b[39m# Run until order of pair is stable\u001b[39;00m\n\u001b[0;32m--> <a href='file:///Users/jeremygoldwasser/Desktop/RankSHAP/shapley_sampling.py?line=165'>166</a>\u001b[0m \u001b[39mwhile\u001b[39;00m my_t_test(diffs_pair[\u001b[39m0\u001b[39;49m], diffs_pair[\u001b[39m1\u001b[39;49m], alpha\u001b[39m=\u001b[39;49malpha)\u001b[39m==\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mfail to reject\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[1;32m    <a href='file:///Users/jeremygoldwasser/Desktop/RankSHAP/shapley_sampling.py?line=166'>167</a>\u001b[0m     diffs_pair_new \u001b[39m=\u001b[39m []\n\u001b[1;32m    <a href='file:///Users/jeremygoldwasser/Desktop/RankSHAP/shapley_sampling.py?line=167'>168</a>\u001b[0m     \u001b[39mfor\u001b[39;00m j \u001b[39min\u001b[39;00m index_pair:\n",
      "File \u001b[0;32m~/Desktop/RankSHAP/shapley_sampling.py:9\u001b[0m, in \u001b[0;36mmy_t_test\u001b[0;34m(feat1, feat2, alpha)\u001b[0m\n\u001b[1;32m      <a href='file:///Users/jeremygoldwasser/Desktop/RankSHAP/shapley_sampling.py?line=6'>7</a>\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(feat2, np\u001b[39m.\u001b[39mndarray): feat2 \u001b[39m=\u001b[39m \u001b[39m-\u001b[39mfeat2\n\u001b[1;32m      <a href='file:///Users/jeremygoldwasser/Desktop/RankSHAP/shapley_sampling.py?line=7'>8</a>\u001b[0m     \u001b[39melse\u001b[39;00m: feat2 \u001b[39m=\u001b[39m [\u001b[39m-\u001b[39mfeat2[j] \u001b[39mfor\u001b[39;00m j \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mlen\u001b[39m(feat2))]\n\u001b[0;32m----> <a href='file:///Users/jeremygoldwasser/Desktop/RankSHAP/shapley_sampling.py?line=8'>9</a>\u001b[0m pval \u001b[39m=\u001b[39m ttest_ind(feat1, feat2, equal_var\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m, \n\u001b[1;32m     <a href='file:///Users/jeremygoldwasser/Desktop/RankSHAP/shapley_sampling.py?line=9'>10</a>\u001b[0m                 alternative\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mtwo-sided\u001b[39;49m\u001b[39m'\u001b[39;49m, random_state\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m)[\u001b[39m1\u001b[39m]\n\u001b[1;32m     <a href='file:///Users/jeremygoldwasser/Desktop/RankSHAP/shapley_sampling.py?line=10'>11</a>\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mreject\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mif\u001b[39;00m pval \u001b[39m<\u001b[39m alpha \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mfail to reject\u001b[39m\u001b[39m\"\u001b[39m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/shap/lib/python3.9/site-packages/scipy/stats/_stats_py.py:6777\u001b[0m, in \u001b[0;36mttest_ind\u001b[0;34m(a, b, axis, equal_var, nan_policy, permutations, random_state, alternative, trim)\u001b[0m\n\u001b[1;32m   <a href='file:///Users/jeremygoldwasser/opt/anaconda3/envs/shap/lib/python3.9/site-packages/scipy/stats/_stats_py.py?line=6773'>6774</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39m0\u001b[39m \u001b[39m<\u001b[39m\u001b[39m=\u001b[39m trim \u001b[39m<\u001b[39m \u001b[39m.5\u001b[39m):\n\u001b[1;32m   <a href='file:///Users/jeremygoldwasser/opt/anaconda3/envs/shap/lib/python3.9/site-packages/scipy/stats/_stats_py.py?line=6774'>6775</a>\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mTrimming percentage should be 0 <= `trim` < .5.\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m-> <a href='file:///Users/jeremygoldwasser/opt/anaconda3/envs/shap/lib/python3.9/site-packages/scipy/stats/_stats_py.py?line=6776'>6777</a>\u001b[0m a, b, axis \u001b[39m=\u001b[39m _chk2_asarray(a, b, axis)\n\u001b[1;32m   <a href='file:///Users/jeremygoldwasser/opt/anaconda3/envs/shap/lib/python3.9/site-packages/scipy/stats/_stats_py.py?line=6778'>6779</a>\u001b[0m \u001b[39m# check both a and b\u001b[39;00m\n\u001b[1;32m   <a href='file:///Users/jeremygoldwasser/opt/anaconda3/envs/shap/lib/python3.9/site-packages/scipy/stats/_stats_py.py?line=6779'>6780</a>\u001b[0m cna, npa \u001b[39m=\u001b[39m _contains_nan(a, nan_policy)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/shap/lib/python3.9/site-packages/scipy/stats/_stats_py.py:109\u001b[0m, in \u001b[0;36m_chk2_asarray\u001b[0;34m(a, b, axis)\u001b[0m\n\u001b[1;32m    <a href='file:///Users/jeremygoldwasser/opt/anaconda3/envs/shap/lib/python3.9/site-packages/scipy/stats/_stats_py.py?line=106'>107</a>\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    <a href='file:///Users/jeremygoldwasser/opt/anaconda3/envs/shap/lib/python3.9/site-packages/scipy/stats/_stats_py.py?line=107'>108</a>\u001b[0m     a \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39masarray(a)\n\u001b[0;32m--> <a href='file:///Users/jeremygoldwasser/opt/anaconda3/envs/shap/lib/python3.9/site-packages/scipy/stats/_stats_py.py?line=108'>109</a>\u001b[0m     b \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39;49masarray(b)\n\u001b[1;32m    <a href='file:///Users/jeremygoldwasser/opt/anaconda3/envs/shap/lib/python3.9/site-packages/scipy/stats/_stats_py.py?line=109'>110</a>\u001b[0m     outaxis \u001b[39m=\u001b[39m axis\n\u001b[1;32m    <a href='file:///Users/jeremygoldwasser/opt/anaconda3/envs/shap/lib/python3.9/site-packages/scipy/stats/_stats_py.py?line=111'>112</a>\u001b[0m \u001b[39mif\u001b[39;00m a\u001b[39m.\u001b[39mndim \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "%run shapley_sampling1\n",
    "# np.random.seed(2)\n",
    "K = 5\n",
    "true_order = np.argsort(np.abs(true_shap_vals))[::-1]\n",
    "true_top_K = true_order[:K]\n",
    "same_top_K = []\n",
    "for i in range(100):\n",
    "    # print(i)\n",
    "    shap_vals2, diffs_all_feats2 = shapley_sampling_adaptive(approx, X_train, xloc, K, \n",
    "                                        mapping_dict=mapping_dict, alpha=0.2, \n",
    "                                        n_perms_btwn_tests=10, n_samples_per_perm=2,\n",
    "                                        n_init=100)\n",
    "    est_top_K = np.argsort(np.abs(shap_vals2))[::-1][:K]\n",
    "    has_same_top_K = np.array_equal(true_top_K, est_top_K)\n",
    "    same_top_K.append(has_same_top_K)\n",
    "    if (i+1) % 5==0: print(i+1, np.round(1-np.mean(same_top_K),2)) # FWER\n",
    "np.round(1-np.mean(same_top_K),2) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Neural net itself\n",
    "- This seems to controls FWER...\n",
    "\n",
    "BRCA\n",
    "- K=1, observe 22% FWER\n",
    "- K=2, observe 30% FWER (slow)\n",
    "\n",
    "Credit\n",
    "- K=1, observe 35% FWER\n",
    "    - Then ran for 1000 iters: only 24% FWER\n",
    "- K=2, observe 29% FWER\n",
    "- K=3, observe 24% FWER\n",
    "\n",
    "Census\n",
    "- K=1-5, observe ~0% FWER (3 and 4, 2%)\n",
    "- K=6, observe 15% FWER\n",
    "- K=7, observe 26% FWER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[243], line 6\u001b[0m\n\u001b[1;32m      4\u001b[0m top_K \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m100\u001b[39m):\n\u001b[0;32m----> 6\u001b[0m     shap_vals2, diffs_all_feats2 \u001b[38;5;241m=\u001b[39m \u001b[43mshapley_sampling_adaptive\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mxloc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mK\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m                                        \u001b[49m\u001b[43mmapping_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmapping_dict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43malpha\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m                                        \u001b[49m\u001b[43mn_perms_btwn_tests\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_samples_per_perm\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m                                        \u001b[49m\u001b[43mn_init\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     10\u001b[0m     est_top_K \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39margsort(np\u001b[38;5;241m.\u001b[39mabs(shap_vals2))[::\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m][:K]\n\u001b[1;32m     11\u001b[0m     top_K\u001b[38;5;241m.\u001b[39mappend(est_top_K)\n",
      "File \u001b[0;32m~/Desktop/RankSHAP/shapley_sampling.py:166\u001b[0m, in \u001b[0;36mshapley_sampling_adaptive\u001b[0;34m(model, X, xloc, K, mapping_dict, alpha, n_perms_btwn_tests, n_samples_per_perm, K_thru_rest, n_init)\u001b[0m\n\u001b[1;32m    <a href='file:///Users/jeremygoldwasser/Desktop/RankSHAP/shapley_sampling.py?line=163'>164</a>\u001b[0m diffs_pair \u001b[39m=\u001b[39m [diffs_all_feats[index_pair[\u001b[39m0\u001b[39m]], diffs_all_feats[index_pair[\u001b[39m1\u001b[39m]]]\n\u001b[1;32m    <a href='file:///Users/jeremygoldwasser/Desktop/RankSHAP/shapley_sampling.py?line=164'>165</a>\u001b[0m \u001b[39m# Run until order of pair is stable\u001b[39;00m\n\u001b[0;32m--> <a href='file:///Users/jeremygoldwasser/Desktop/RankSHAP/shapley_sampling.py?line=165'>166</a>\u001b[0m \u001b[39mwhile\u001b[39;00m my_t_test(diffs_pair[\u001b[39m0\u001b[39;49m], diffs_pair[\u001b[39m1\u001b[39;49m], alpha\u001b[39m=\u001b[39;49malpha)\u001b[39m==\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mfail to reject\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[1;32m    <a href='file:///Users/jeremygoldwasser/Desktop/RankSHAP/shapley_sampling.py?line=166'>167</a>\u001b[0m     diffs_pair_new \u001b[39m=\u001b[39m []\n\u001b[1;32m    <a href='file:///Users/jeremygoldwasser/Desktop/RankSHAP/shapley_sampling.py?line=167'>168</a>\u001b[0m     \u001b[39mfor\u001b[39;00m j \u001b[39min\u001b[39;00m index_pair:\n",
      "File \u001b[0;32m~/Desktop/RankSHAP/shapley_sampling.py:9\u001b[0m, in \u001b[0;36mmy_t_test\u001b[0;34m(feat1, feat2, alpha)\u001b[0m\n\u001b[1;32m      <a href='file:///Users/jeremygoldwasser/Desktop/RankSHAP/shapley_sampling.py?line=6'>7</a>\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(feat2, np\u001b[39m.\u001b[39mndarray): feat2 \u001b[39m=\u001b[39m \u001b[39m-\u001b[39mfeat2\n\u001b[1;32m      <a href='file:///Users/jeremygoldwasser/Desktop/RankSHAP/shapley_sampling.py?line=7'>8</a>\u001b[0m     \u001b[39melse\u001b[39;00m: feat2 \u001b[39m=\u001b[39m [\u001b[39m-\u001b[39mfeat2[j] \u001b[39mfor\u001b[39;00m j \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mlen\u001b[39m(feat2))]\n\u001b[0;32m----> <a href='file:///Users/jeremygoldwasser/Desktop/RankSHAP/shapley_sampling.py?line=8'>9</a>\u001b[0m pval \u001b[39m=\u001b[39m ttest_ind(feat1, feat2, equal_var\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m, \n\u001b[1;32m     <a href='file:///Users/jeremygoldwasser/Desktop/RankSHAP/shapley_sampling.py?line=9'>10</a>\u001b[0m                 alternative\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mtwo-sided\u001b[39;49m\u001b[39m'\u001b[39;49m, random_state\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m)[\u001b[39m1\u001b[39m]\n\u001b[1;32m     <a href='file:///Users/jeremygoldwasser/Desktop/RankSHAP/shapley_sampling.py?line=10'>11</a>\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mreject\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mif\u001b[39;00m pval \u001b[39m<\u001b[39m alpha \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mfail to reject\u001b[39m\u001b[39m\"\u001b[39m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/shap/lib/python3.9/site-packages/scipy/stats/_stats_py.py:6777\u001b[0m, in \u001b[0;36mttest_ind\u001b[0;34m(a, b, axis, equal_var, nan_policy, permutations, random_state, alternative, trim)\u001b[0m\n\u001b[1;32m   <a href='file:///Users/jeremygoldwasser/opt/anaconda3/envs/shap/lib/python3.9/site-packages/scipy/stats/_stats_py.py?line=6773'>6774</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39m0\u001b[39m \u001b[39m<\u001b[39m\u001b[39m=\u001b[39m trim \u001b[39m<\u001b[39m \u001b[39m.5\u001b[39m):\n\u001b[1;32m   <a href='file:///Users/jeremygoldwasser/opt/anaconda3/envs/shap/lib/python3.9/site-packages/scipy/stats/_stats_py.py?line=6774'>6775</a>\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mTrimming percentage should be 0 <= `trim` < .5.\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m-> <a href='file:///Users/jeremygoldwasser/opt/anaconda3/envs/shap/lib/python3.9/site-packages/scipy/stats/_stats_py.py?line=6776'>6777</a>\u001b[0m a, b, axis \u001b[39m=\u001b[39m _chk2_asarray(a, b, axis)\n\u001b[1;32m   <a href='file:///Users/jeremygoldwasser/opt/anaconda3/envs/shap/lib/python3.9/site-packages/scipy/stats/_stats_py.py?line=6778'>6779</a>\u001b[0m \u001b[39m# check both a and b\u001b[39;00m\n\u001b[1;32m   <a href='file:///Users/jeremygoldwasser/opt/anaconda3/envs/shap/lib/python3.9/site-packages/scipy/stats/_stats_py.py?line=6779'>6780</a>\u001b[0m cna, npa \u001b[39m=\u001b[39m _contains_nan(a, nan_policy)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/shap/lib/python3.9/site-packages/scipy/stats/_stats_py.py:108\u001b[0m, in \u001b[0;36m_chk2_asarray\u001b[0;34m(a, b, axis)\u001b[0m\n\u001b[1;32m    <a href='file:///Users/jeremygoldwasser/opt/anaconda3/envs/shap/lib/python3.9/site-packages/scipy/stats/_stats_py.py?line=105'>106</a>\u001b[0m     outaxis \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n\u001b[1;32m    <a href='file:///Users/jeremygoldwasser/opt/anaconda3/envs/shap/lib/python3.9/site-packages/scipy/stats/_stats_py.py?line=106'>107</a>\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> <a href='file:///Users/jeremygoldwasser/opt/anaconda3/envs/shap/lib/python3.9/site-packages/scipy/stats/_stats_py.py?line=107'>108</a>\u001b[0m     a \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39;49masarray(a)\n\u001b[1;32m    <a href='file:///Users/jeremygoldwasser/opt/anaconda3/envs/shap/lib/python3.9/site-packages/scipy/stats/_stats_py.py?line=108'>109</a>\u001b[0m     b \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39masarray(b)\n\u001b[1;32m    <a href='file:///Users/jeremygoldwasser/opt/anaconda3/envs/shap/lib/python3.9/site-packages/scipy/stats/_stats_py.py?line=109'>110</a>\u001b[0m     outaxis \u001b[39m=\u001b[39m axis\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "%run shapley_sampling1\n",
    "# np.random.seed(2)\n",
    "K = 2\n",
    "top_K = []\n",
    "for i in range(100):\n",
    "    shap_vals2, diffs_all_feats2 = shapley_sampling_adaptive(model, X_train, xloc, K, \n",
    "                                        mapping_dict=mapping_dict, alpha=0.2, \n",
    "                                        n_perms_btwn_tests=10, n_samples_per_perm=1,\n",
    "                                        n_init=100)\n",
    "    est_top_K = np.argsort(np.abs(shap_vals2))[::-1][:K]\n",
    "    top_K.append(est_top_K)\n",
    "    if (i+1) % 5==0: \n",
    "        print(i+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2\n",
      "[50, 50, 50, 50, 5950, 9600, 320, 50, 4160, 240, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50]\n"
     ]
    }
   ],
   "source": [
    "top_K = np.array(top_K)\n",
    "most_common_row = mode_rows(top_K)\n",
    "ct = 0\n",
    "for i in range(top_K.shape[0]):\n",
    "    if np.array_equal(most_common_row, top_K[i]):\n",
    "        ct += 1\n",
    "print(np.round(1 - ct / top_K.shape[0], 2)) # FWER\n",
    "print([len(diffs_all_feats2[j]) for j in range(len(diffs_all_feats2))])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "768407c71a286f507fab4bce553d71b5cbd766c247b76eb598ef769225202bc3"
  },
  "kernelspec": {
   "display_name": "Python 3.9.16 ('shap')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
