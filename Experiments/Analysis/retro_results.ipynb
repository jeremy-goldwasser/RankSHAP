{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "import pathlib\n",
    "import sys\n",
    "from os.path import join\n",
    "path_to_file = str(pathlib.Path().resolve())\n",
    "dir_path = join(path_to_file, \"../../\")\n",
    "sys.path.append(join(dir_path, \"HelperFiles\"))\n",
    "from helper import *\n",
    "results_path = join(dir_path, \"Experiments\", \"Results\", \"Retrospective\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_retro_fwer(GTranks, rankings, nVerified, alphaIdx):\n",
    "    nStable = np.sum(nVerified[:,alphaIdx] > 0)\n",
    "    N_runs, _ = rankings.shape\n",
    "    if nStable <= 0.05*N_runs: # Majority unverified\n",
    "        return None\n",
    "    prop_stable = 0\n",
    "    # Number of runs with at least one stable rank\n",
    "    for runIdx in range(N_runs):\n",
    "        nVerif = nVerified[runIdx,alphaIdx]\n",
    "        if nVerif > 0:\n",
    "            stableRanks = rankings[runIdx,:nVerif]\n",
    "            was_stable = np.array_equal(stableRanks, GTranks[:nVerif])\n",
    "            prop_stable += was_stable\n",
    "    prop_stable /= nStable\n",
    "    fwer = 1 - prop_stable\n",
    "    return round(fwer,3)\n",
    "\n",
    "def calc_avg_fwers(all_fwers):\n",
    "    # Given N_alphas x N_pts numpy array (3x10) of fwers\n",
    "    N_alphas, N_pts = all_fwers.shape\n",
    "    avg_fwers = []\n",
    "    for i in range(N_alphas):\n",
    "        fwers = []\n",
    "        for j in range(N_pts):\n",
    "            if all_fwers[i,j] is not None:\n",
    "                fwers.append(all_fwers[i,j])\n",
    "        avg_fwers.append(np.mean(fwers))\n",
    "    return np.round(avg_fwers, 3)\n",
    "\n",
    "def calc_prop_controlled(all_fwers, alphas):\n",
    "    # Given N_alphas x N_pts numpy array (3x10) of fwers\n",
    "    N_alphas, N_pts = all_fwers.shape\n",
    "    prop_controlled = []\n",
    "    for i in range(N_alphas):\n",
    "        controlled = []\n",
    "        for j in range(N_pts):\n",
    "            if all_fwers[i,j] is not None:\n",
    "                controlled.append(all_fwers[i,j] <= alphas[i])\n",
    "        prop_controlled.append(np.mean(controlled))\n",
    "    return np.round(prop_controlled, 3)\n",
    "\n",
    "def calc_all_fwers(verif, ranks, avgRanks):\n",
    "    fwers_all = []\n",
    "    N_pts, N_runs, N_alphas = verif.shape\n",
    "    for alphaIdx in range(N_alphas):\n",
    "        fwers = []\n",
    "        for ptIdx in range(N_pts):\n",
    "            GTranks = avgRanks[ptIdx]\n",
    "            fwer = calc_retro_fwer(GTranks, ranks[ptIdx], verif[ptIdx], alphaIdx)\n",
    "            fwers.append(fwer)\n",
    "        fwers_all.append(fwers)\n",
    "    return np.array(fwers_all)\n",
    "    \n",
    "alphas = [0.05, 0.1, 0.2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Ranks Verified, SS: [2. 2. 1. 0. 2. 2. 2. 0. 2. 0.]\n",
      "KernelSHAP: [1. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n"
     ]
    }
   ],
   "source": [
    "dataset = \"bank\"\n",
    "ssTitle = \"ss_\" + dataset\n",
    "kshapTitle = \"kernelshap_\" + dataset\n",
    "with open(join(results_path, ssTitle+\"_N_verified\"), \"rb\") as fp:\n",
    "    ssVerif = pickle.load(fp)\n",
    "with open(join(results_path, kshapTitle+\"_N_verified\"), \"rb\") as fp:\n",
    "    kshapVerif = pickle.load(fp)\n",
    "\n",
    "with open(join(results_path, ssTitle+\"_shap_vals\"), \"rb\") as fp:\n",
    "    ssVals = pickle.load(fp)\n",
    "    ssRanks = shap_vals_to_ranks(ssVals, abs=True)\n",
    "with open(join(results_path, kshapTitle+\"_shap_vals\"), \"rb\") as fp:\n",
    "    kshapVals = pickle.load(fp)\n",
    "    kshapRanks = shap_vals_to_ranks(kshapVals, abs=True)\n",
    "N_pts, N_runs, N_alphas = ssVerif.shape\n",
    "\n",
    "print(\"# Ranks Verified, SS:\", np.median(ssVerif[:,:,1], axis=1))\n",
    "print(\"KernelSHAP:\", np.median(kshapVerif[:,:,1], axis=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KernelSHAP is verifying fewer ranks than Shapley Sampling. Is it also more unstable, or is the variance/test just bad?\n",
    "- YES: it's considerably more unstable. Fuck.\n",
    "- How the fuck is this happening?????\n",
    "\n",
    "and how different are its rankings?\n",
    "- The rankings are decent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.002466453691209922\n",
      "0.009328117455284862\n",
      "[11  8 15  6  9]\n",
      "[11  8 15  6  4]\n",
      "##########\n",
      "[11  8 15  9  6]\n",
      "[11  8  6 15  4]\n",
      "##########\n",
      "[ 8  6  3 15  9]\n",
      "[ 8 15  6  3 14]\n",
      "##########\n"
     ]
    }
   ],
   "source": [
    "print(np.sum(np.var(ssVals, axis=1)))\n",
    "print(np.sum(np.var(kshapVals, axis=1)))\n",
    "for i in range(3):\n",
    "    print(ssRanks[i,0, :5])\n",
    "    print(kshapRanks[i,0, :5])\n",
    "    print(\"#\"*10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.002 0.011 0.028]\n",
      "[0. 0. 0.]\n",
      "[1. 1. 1.]\n",
      "[1. 1. 1.]\n"
     ]
    }
   ],
   "source": [
    "avgSS, avgKshap = np.mean(ssVals, axis=1), np.mean(kshapVals, axis=1)\n",
    "avgSSRanks = np.array([get_ranking(avgSS[i]) for i in range(N_pts)])\n",
    "avgKshapRanks = np.array([get_ranking(avgKshap[i]) for i in range(N_pts)])\n",
    "    \n",
    "ssFwers_all = calc_all_fwers(ssVerif, ssRanks, avgSSRanks)\n",
    "kshapFwers_all = calc_all_fwers(kshapVerif, kshapRanks, avgKshapRanks)\n",
    "\n",
    "print(calc_avg_fwers(ssFwers_all))\n",
    "print(calc_avg_fwers(kshapFwers_all))\n",
    "\n",
    "print(calc_prop_controlled(ssFwers_all, alphas))\n",
    "print(calc_prop_controlled(kshapFwers_all, alphas))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "bank good; brca good; breast_cancer good; census good; credit good\n",
    "- all good - but very sparse\n",
    "\n",
    "Whatever, let's make a table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[ 0.  1.  2.]\n",
      "  [ 0.  1.  3.]\n",
      "  [ 1. 10. 16.]\n",
      "  [ 2.  2.  4.]\n",
      "  [ 1.  3.  6.]]\n",
      "\n",
      " [[ 0.  0.  0.]\n",
      "  [ 0.  0.  0.]\n",
      "  [ 0.  0.  0.]\n",
      "  [ 0.  0.  0.]\n",
      "  [ 0.  0.  0.]]]\n",
      "##########\n",
      "[[[1.  1.  1. ]\n",
      "  [1.  1.  1. ]\n",
      "  [1.  0.6 0.6]\n",
      "  [0.9 1.  1. ]\n",
      "  [0.9 0.9 1. ]]\n",
      "\n",
      " [[1.  1.  1. ]\n",
      "  [1.  1.  1. ]\n",
      "  [1.  1.  1. ]\n",
      "  [1.  1.  1. ]\n",
      "  [1.  1.  1. ]]]\n"
     ]
    }
   ],
   "source": [
    "datasets = [\"census\", \"bank\", \"brca\", \"breast_cancer\", \"credit\"]\n",
    "props_controlled_ss, props_controlled_kshap = [], []\n",
    "fwers_ss, fwers_kshap = [], []\n",
    "for dataset in datasets:\n",
    "    ssTitle = \"ss_\" + dataset\n",
    "    kshapTitle = \"kernelshap_\" + dataset\n",
    "    with open(join(results_path, ssTitle+\"_N_verified\"), \"rb\") as fp:\n",
    "        ssVerif = pickle.load(fp)\n",
    "    with open(join(results_path, kshapTitle+\"_N_verified\"), \"rb\") as fp:\n",
    "        kshapVerif = pickle.load(fp)\n",
    "\n",
    "    with open(join(results_path, ssTitle+\"_shap_vals\"), \"rb\") as fp:\n",
    "        ssVals = pickle.load(fp)\n",
    "        ssRanks = shap_vals_to_ranks(ssVals, abs=True)\n",
    "    with open(join(results_path, kshapTitle+\"_shap_vals\"), \"rb\") as fp:\n",
    "        kshapVals = pickle.load(fp)\n",
    "        kshapRanks = shap_vals_to_ranks(kshapVals, abs=True)\n",
    "    N_pts, N_runs, N_alphas = ssVerif.shape\n",
    "\n",
    "    avgSS, avgKshap = np.mean(ssVals, axis=1), np.mean(kshapVals, axis=1)\n",
    "    avgSSRanks = np.array([get_ranking(avgSS[i]) for i in range(N_pts)])\n",
    "    avgKshapRanks = np.array([get_ranking(avgKshap[i]) for i in range(N_pts)])\n",
    "        \n",
    "    ssFwers_all = calc_all_fwers(ssVerif, ssRanks, avgSSRanks)\n",
    "    kshapFwers_all = calc_all_fwers(kshapVerif, kshapRanks, avgKshapRanks)\n",
    "\n",
    "    fwers_ss.append(calc_avg_fwers(ssFwers_all))\n",
    "    fwers_kshap.append(calc_avg_fwers(kshapFwers_all))\n",
    "\n",
    "    props_controlled_ss.append(calc_prop_controlled(ssFwers_all, alphas))\n",
    "    props_controlled_kshap.append(calc_prop_controlled(kshapFwers_all, alphas))\n",
    "\n",
    "fwers = np.array([fwers_ss, fwers_kshap])\n",
    "props_controlled = np.array([props_controlled_ss, props_controlled_kshap])\n",
    "print(np.round(fwers*100))\n",
    "print(\"#\"*10)\n",
    "print(props_controlled)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "768407c71a286f507fab4bce553d71b5cbd766c247b76eb598ef769225202bc3"
  },
  "kernelspec": {
   "display_name": "Python 3.9.16 ('shap')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
