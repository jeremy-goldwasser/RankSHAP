{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jeremygoldwasser/Desktop/RankSHAP/kernelshap.py:285: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "  if var_method is \"ls\":\n",
      "/Users/jeremygoldwasser/opt/anaconda3/envs/shap/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "# import sage\n",
    "# from scipy.stats import rankdata\n",
    "from scipy.stats import ttest_ind, t\n",
    "import sys\n",
    "from helper import *\n",
    "from kernelshap import *\n",
    "# from os.path import join\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import TensorDataset, DataLoader, WeightedRandomSampler\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(1)\n",
    "data = pd.read_csv(\"Data/brca_small.csv\")\n",
    "X = data.values[:, :-1][:,:20]\n",
    "Y = data.values[:, -1]\n",
    "Y = (Y==2).astype(int) # Formulate as binary classification problem\n",
    "\n",
    "# Split data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=100, random_state=0)\n",
    "\n",
    "# Normalize\n",
    "mean = X_train.mean(axis=0)\n",
    "std = X_train.std(axis=0)\n",
    "X_train = (X_train - mean) / std\n",
    "X_test = (X_test - mean) / std\n",
    "d = X_train.shape[1]\n",
    "mapping_dict = None\n",
    "\n",
    "# Compute mean and covariance of training data\n",
    "feature_means = np.mean(X_train, axis=0)\n",
    "cov_mat = correct_cov(np.cov(X_train, rowvar=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # df = sage.datasets.credit()\n",
    "# # df.to_csv(\"Data/credit.csv\")\n",
    "# df = pd.read_csv(\"Data/credit.csv\", index_col=0)\n",
    "\n",
    "# # Property, other installment, housing, job, status of checking act, credit history, purpose, savings, employment since, marital status, old debtors\n",
    "# n = df.shape[0]\n",
    "# X_df = df.drop([\"Good Customer\"], axis=1)\n",
    "# y = df[\"Good Customer\"]\n",
    "\n",
    "# categorical_columns = [\n",
    "#     'Checking Status', 'Credit History', 'Purpose', #'Credit Amount', # It's listed but has 923 unique values\n",
    "#     'Savings Account/Bonds', 'Employment Since', 'Personal Status',\n",
    "#     'Debtors/Guarantors', 'Property Type', 'Other Installment Plans',\n",
    "#     'Housing Ownership', 'Job', #'Telephone', 'Foreign Worker' # These are just binary\n",
    "# ]\n",
    "# X_binarized = pd.get_dummies(X_df, columns=categorical_columns)\n",
    "\n",
    "# mapping_dict = {}\n",
    "# for i, col in enumerate(X_df.columns):\n",
    "#     bin_cols = []\n",
    "#     for j, bin_col in enumerate(X_binarized.columns):\n",
    "#         if bin_col.startswith(col):\n",
    "#             bin_cols.append(j)\n",
    "#     mapping_dict[i] = bin_cols\n",
    "\n",
    "# np.random.seed(1)\n",
    "# X_norm = (X_binarized-X_binarized.min())/(X_binarized.max()-X_binarized.min())\n",
    "# n_train = round(n*0.8)\n",
    "# train_idx = np.random.choice(n, n_train, replace=False)\n",
    "# X_train, y_train = X_norm.iloc[train_idx].to_numpy(), y.iloc[train_idx].to_numpy()\n",
    "# test_idx = np.setdiff1d(np.arange(n),train_idx)\n",
    "# X_test, y_test = X_norm.iloc[test_idx].to_numpy(), y.iloc[test_idx].to_numpy()\n",
    "# d = X_df.shape[1]\n",
    "# d_bin = X_train.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bank dataset\n",
    "# import sage\n",
    "# from sklearn.model_selection import train_test_split\n",
    "\n",
    "# df = sage.datasets.bank()\n",
    "# df.Default = df.Default.map({'no': 0, 'yes': 1})\n",
    "# df.Housing = df.Housing.map({'no': 0, 'yes': 1})\n",
    "# df.Loan = df.Loan.map({'no': 0, 'yes': 1})\n",
    "# df.columns = df.columns.str.replace(' ', '_')\n",
    "# df_bin = pd.get_dummies(df)\n",
    "\n",
    "# # That's literally it. Note this mapping dict is a little different.\n",
    "# train, test = train_test_split(\n",
    "#     df_bin.values, test_size=int(0.1 * len(df_bin.values)), random_state=123)\n",
    "\n",
    "# suc_idx = df_bin.columns.get_loc(\"Success\")\n",
    "# y_train = train[:, suc_idx].copy().astype(int)\n",
    "# y_test = test[:, suc_idx].copy().astype(int)\n",
    "# X_train = np.delete(train, suc_idx, axis=1).astype(\"float64\")\n",
    "# X_test = np.delete(test, suc_idx, axis=1).astype(\"float64\")\n",
    "\n",
    "# # Get mapping dict\n",
    "# X_df = df_bin.drop([\"Success\"], axis=1)\n",
    "# mapping_dict = {}\n",
    "# for i, col in enumerate(df.columns):\n",
    "#     bin_cols = []\n",
    "#     for j, bin_col in enumerate(X_df.columns):\n",
    "#         if bin_col.startswith(col):\n",
    "#             bin_cols.append(j)\n",
    "#     mapping_dict[i] = bin_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Adult census income dataset\n",
    "# import shap\n",
    "# X, y = shap.datasets.adult()\n",
    "# X_display, y_display = shap.datasets.adult(display=True)\n",
    "# X_binarized = pd.get_dummies(X_display)\n",
    "\n",
    "# mapping_dict = {}\n",
    "# for i, col in enumerate(X_display.columns):\n",
    "#     bin_cols = []\n",
    "#     for j, bin_col in enumerate(X_binarized.columns):\n",
    "#         if bin_col.startswith(col):\n",
    "#             bin_cols.append(j)\n",
    "#     mapping_dict[i] = bin_cols\n",
    "\n",
    "# X_norm = (X_binarized-X_binarized.min())/(X_binarized.max()-X_binarized.min())\n",
    "# y_int = y_display.astype(\"int8\")\n",
    "\n",
    "# # Split into training and test sets\n",
    "# np.random.seed(1)\n",
    "# n, d = X_norm.shape\n",
    "# n_train = round(n*0.75)\n",
    "# train_idx = np.random.choice(n, size=n_train, replace=False)\n",
    "# X_train_pd, y_train = X_norm.iloc[train_idx], y_int[train_idx]\n",
    "# X_train = X_train_pd.to_numpy()\n",
    "\n",
    "# test_idx = np.setdiff1d(list(range(n)), train_idx)\n",
    "# X_test_pd, y_test = X_norm.iloc[test_idx], y_int[test_idx]\n",
    "# X_test = X_test_pd.to_numpy()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define neural network, train, and move to numpy\n",
    "- Trains with balanced weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class imbalance: 55%\n",
      "NN 79% accuracy\n"
     ]
    }
   ],
   "source": [
    "class NeuralNet(nn.Module):\n",
    "    # def __init__(self, input_size, hidden_size, output_size):\n",
    "    def __init__(self, input_size, hidden_size1, hidden_size2, output_size):\n",
    "        super(NeuralNet, self).__init__()\n",
    "        # self.linear1 = nn.Linear(input_size, hidden_size)\n",
    "        self.linear1 = nn.Linear(input_size, hidden_size1)\n",
    "        self.tanh = nn.Tanh()\n",
    "        self.linear2 = nn.Linear(hidden_size1, hidden_size2)\n",
    "        self.linear3 = nn.Linear(hidden_size2, output_size)\n",
    "        # self.linear2 = nn.Linear(hidden_size, output_size)\n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.linear1(x)\n",
    "        out = self.tanh(out)\n",
    "        out = self.linear2(out)\n",
    "        out = self.tanh(out)\n",
    "        out = self.linear3(out)\n",
    "        out = self.softmax(out)\n",
    "        return out\n",
    "\n",
    "# Convert the input and label data to PyTorch tensors\n",
    "inputs = torch.tensor(X_train, dtype=torch.float32)\n",
    "labels = torch.tensor(y_train, dtype=torch.long)\n",
    "\n",
    "# Compute the class weights\n",
    "class_counts = torch.bincount(labels)\n",
    "num_samples = len(labels)\n",
    "class_weights = 1.0 / class_counts.float()\n",
    "sample_weights = class_weights[labels]\n",
    "\n",
    "# Create a sampler with balanced weights\n",
    "sampler = WeightedRandomSampler(weights=sample_weights, num_samples=num_samples, replacement=True)\n",
    "\n",
    "# Create a DataLoader with the sampler\n",
    "dataset = TensorDataset(inputs, labels)\n",
    "dataloader = DataLoader(dataset, batch_size=32, sampler=sampler)\n",
    "# dataloader = DataLoader(dataset, batch_size=32)\n",
    "\n",
    "torch.manual_seed(0)\n",
    "\n",
    "# Create an instance\n",
    "# net = NeuralNet(input_size=X_train.shape[1], hidden_size=50, output_size=2)\n",
    "net = NeuralNet(input_size=X_train.shape[1], hidden_size1=100, hidden_size2=50, output_size=2)\n",
    "# Define the loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(net.parameters(), lr=0.001)#.01\n",
    "\n",
    "# Iterate over the training data in batches\n",
    "num_epochs = 20\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    for inputs, labels in dataloader:\n",
    "        optimizer.zero_grad()\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    # print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {loss.item():.4f}\")\n",
    "\n",
    "def neural_net(x):\n",
    "    output = net(x)[0,1] if x.shape[0]==1 else net(x)[:,1]\n",
    "    return output\n",
    "\n",
    "def compute_hessian(x):\n",
    "    if not torch.is_tensor(x):\n",
    "        x = torch.tensor(x, dtype=torch.float32)\n",
    "    dim = x.shape[1]\n",
    "    hessian = torch.autograd.functional.hessian(neural_net, x)\n",
    "    hessian = hessian.reshape((dim,dim)).detach().numpy()\n",
    "    return hessian\n",
    "\n",
    "def fmodel(x):\n",
    "    if not torch.is_tensor(x):\n",
    "        x = torch.tensor(x, dtype=torch.float32)\n",
    "    return neural_net(x).detach().numpy()\n",
    "\n",
    "print(\"Class imbalance: {}%\".format(round(100*(max(np.mean(y_test), 1-np.mean(y_test))))))\n",
    "Y_preds = (fmodel(X_test) > 0.5).astype(\"int\")\n",
    "print(\"NN {}% accuracy\".format(round(np.mean(Y_preds == y_test)*100)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-8.97556459367533e-05\n",
      "-8.9805e-05\n"
     ]
    }
   ],
   "source": [
    "%run helper\n",
    "# Compute mean and covariance of training data\n",
    "feature_means = np.mean(X_train, axis=0)\n",
    "cov_mat = correct_cov(np.cov(X_train, rowvar=False))\n",
    "\n",
    "# Select point and compute its gradient and hessian\n",
    "xloc = X_test[0:1]\n",
    "xloc_torch = torch.tensor(xloc, dtype=torch.float32).requires_grad_(True)\n",
    "y_pred = net(xloc_torch)[0,1]\n",
    "y_pred.backward()\n",
    "gradient = xloc_torch.grad.detach().numpy().reshape((xloc.shape[1], 1))\n",
    "hessian = compute_hessian(xloc)\n",
    "\n",
    "# Obtain true SHAP values and verify their feasibility\n",
    "true_shap_vals = compute_shap_vals_quadratic(xloc, gradient, hessian, feature_means, cov_mat, mapping_dict=mapping_dict)\n",
    "\n",
    "y_pred = y_pred.detach().numpy()\n",
    "def approx(input):\n",
    "    return f_second_order_approx(y_pred,input,xloc,gradient,hessian)\n",
    "\n",
    "print(approx(xloc) - np.mean(approx(X_train)))\n",
    "print(np.sum(true_shap_vals))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KernelSHAP\n",
    "Doesn't converge w/ LS variance bc it's too high --> test stats too low\n",
    "\n",
    "- We still do the new t-test here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[21], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m# np.random.seed(1)\u001b[39;00m\n\u001b[1;32m      3\u001b[0m K \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m3\u001b[39m\n\u001b[0;32m----> 4\u001b[0m kshap_ests, kshap_vars, n_subsets \u001b[38;5;241m=\u001b[39m \u001b[43mkernelshap\u001b[49m\u001b[43m(\u001b[49m\u001b[43mapprox\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mxloc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mK\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m            \u001b[49m\u001b[43mn_perms_btwn_tests\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m500\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_samples_per_perm\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43malpha\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_init\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m500\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;66;43;03m#n=50,\u001b[39;49;00m\n\u001b[1;32m      6\u001b[0m \u001b[43m            \u001b[49m\u001b[43mmapping_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmapping_dict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_n_perms\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10000\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvar_method\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mls\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28mprint\u001b[39m(n_subsets)\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28mprint\u001b[39m(get_ordering(true_shap_vals))\n",
      "File \u001b[0;32m~/Desktop/RankSHAP/kernelshap.py:286\u001b[0m, in \u001b[0;36mkernelshap\u001b[0;34m(model, X, xloc, K, n_perms_btwn_tests, n_samples_per_perm, mapping_dict, alpha, K_thru_rest, perm_test, n, var_method, n_init, unbiased, max_n_perms)\u001b[0m\n\u001b[1;32m    <a href='file:///Users/jeremygoldwasser/Desktop/RankSHAP/kernelshap.py?line=283'>284</a>\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    <a href='file:///Users/jeremygoldwasser/Desktop/RankSHAP/kernelshap.py?line=284'>285</a>\u001b[0m     \u001b[39mif\u001b[39;00m var_method \u001b[39mis\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mls\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[0;32m--> <a href='file:///Users/jeremygoldwasser/Desktop/RankSHAP/kernelshap.py?line=285'>286</a>\u001b[0m         kshap_vars \u001b[39m=\u001b[39m compute_kshap_vars_ls(coalition_vars, coalitions)\n\u001b[1;32m    <a href='file:///Users/jeremygoldwasser/Desktop/RankSHAP/kernelshap.py?line=286'>287</a>\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    <a href='file:///Users/jeremygoldwasser/Desktop/RankSHAP/kernelshap.py?line=287'>288</a>\u001b[0m         kshap_vars \u001b[39m=\u001b[39m compute_kshap_vars_boot(y_pred, avg_pred, coalitions, \n\u001b[1;32m    <a href='file:///Users/jeremygoldwasser/Desktop/RankSHAP/kernelshap.py?line=288'>289</a>\u001b[0m                 coalition_values, n_boot\u001b[39m=\u001b[39m\u001b[39m250\u001b[39m)\n",
      "File \u001b[0;32m~/Desktop/RankSHAP/kernelshap.py:147\u001b[0m, in \u001b[0;36mcompute_kshap_vars_ls\u001b[0;34m(var_values, coalitions)\u001b[0m\n\u001b[1;32m    <a href='file:///Users/jeremygoldwasser/Desktop/RankSHAP/kernelshap.py?line=143'>144</a>\u001b[0m C \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mdiag(np\u001b[39m.\u001b[39mones(d)) \u001b[39m-\u001b[39m np\u001b[39m.\u001b[39mouter(ones_vec,ones_vec) \u001b[39m@\u001b[39m A_inv\u001b[39m/\u001b[39mnp\u001b[39m.\u001b[39mmatmul(np\u001b[39m.\u001b[39mmatmul(ones_vec\u001b[39m.\u001b[39mT, A_inv), ones_vec)\n\u001b[1;32m    <a href='file:///Users/jeremygoldwasser/Desktop/RankSHAP/kernelshap.py?line=145'>146</a>\u001b[0m inv_ZT \u001b[39m=\u001b[39m A_inv \u001b[39m@\u001b[39m C \u001b[39m@\u001b[39m coalitions\u001b[39m.\u001b[39mT\n\u001b[0;32m--> <a href='file:///Users/jeremygoldwasser/Desktop/RankSHAP/kernelshap.py?line=146'>147</a>\u001b[0m kshap_vars_ls \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mdiagonal(inv_ZT \u001b[39m@\u001b[39;49m var_values \u001b[39m@\u001b[39m inv_ZT\u001b[39m.\u001b[39mT)\n\u001b[1;32m    <a href='file:///Users/jeremygoldwasser/Desktop/RankSHAP/kernelshap.py?line=147'>148</a>\u001b[0m \u001b[39mreturn\u001b[39;00m kshap_vars_ls\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "%run kernelshap\n",
    "# np.random.seed(1)\n",
    "K = 3\n",
    "kshap_ests, kshap_vars, n_subsets = kernelshap(approx, X_train, xloc, K, \n",
    "            n_perms_btwn_tests=500, n_samples_per_perm=10, alpha=0.2, n_init=500, #n=50,\n",
    "            mapping_dict=mapping_dict, max_n_perms=10000, var_method=\"ls\")\n",
    "print(n_subsets)\n",
    "print(get_ordering(true_shap_vals))\n",
    "print(get_ordering(kshap_ests))\n",
    "print(np.sum(kshap_ests))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bootstrapped variance works!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23000\n",
      "[ 8  3  2  4  7  0 10 11  5  9  6  1]\n",
      "[ 8  3  2  4  7  0 10 11  5  6  1  9]\n",
      "0.025785144797551167\n"
     ]
    }
   ],
   "source": [
    "%run kernelshap\n",
    "# np.random.seed(1)\n",
    "K = 3\n",
    "kshap_ests, kshap_vars, n_subsets = kernelshap(approx, X_train, xloc, K, \n",
    "            n_perms_btwn_tests=500, n_samples_per_perm=10, alpha=0.2, n_init=500, #n=50,\n",
    "            mapping_dict=mapping_dict, max_n_perms=50000, var_method=\"boot\")\n",
    "print(n_subsets)\n",
    "print(get_ordering(true_shap_vals))\n",
    "print(get_ordering(kshap_ests))\n",
    "print(np.sum(kshap_ests))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unbiased method does not produce SHAP values that converge. Maybe there's a bug... not sure what's going on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reached max number of permutations.\n",
      "[ 3  8  5  0  9  2  6  7  4 10 11  1]\n",
      "0.025785144797551188\n"
     ]
    }
   ],
   "source": [
    "kshap_ests, kshap_vars, n_subsets = kernelshap(approx, X_train, xloc, K, \n",
    "            n_perms_btwn_tests=5000, n_samples_per_perm=10, alpha=0.2, n_init=500, #n=50,\n",
    "            mapping_dict=mapping_dict, max_n_perms=50000, unbiased=True)\n",
    "print(get_ordering(kshap_ests))\n",
    "print(np.sum(kshap_ests))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simulation\n",
    "\n",
    "K=1: Control FWER! 20% w/ 50 sims, alpha=0.2\n",
    "- This is with bootstrapped variance and standard KernelSHAP. For n in t-test DF, just use # perms.\n",
    "- LS variance does not work, nor does unbiased KernelSHAP.\n",
    "\n",
    "K=3: Often reaches 10k perms and cuts out... but that's OK: The FWER is 40%, indicating it hasn't converged."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[8]\n",
      "####################\n",
      "0\n",
      "Reached max number of permutations.\n",
      "1\n",
      "Reached max number of permutations.\n",
      "2\n",
      "Reached max number of permutations.\n",
      "3\n",
      "Reached max number of permutations.\n",
      "4\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[31], line 11\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m50\u001b[39m):\n\u001b[1;32m     10\u001b[0m     \u001b[38;5;28mprint\u001b[39m(i)\n\u001b[0;32m---> 11\u001b[0m     kshap_ests, kshap_vars, n_subsets \u001b[38;5;241m=\u001b[39m \u001b[43mkernelshap\u001b[49m\u001b[43m(\u001b[49m\u001b[43mapprox\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mxloc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mK\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     12\u001b[0m \u001b[43m            \u001b[49m\u001b[43mn_perms_btwn_tests\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m500\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_samples_per_perm\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43malpha\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_init\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m500\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;66;43;03m#n=50,\u001b[39;49;00m\n\u001b[1;32m     13\u001b[0m \u001b[43m            \u001b[49m\u001b[43mmapping_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmapping_dict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_n_perms\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10000\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43munbiased\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[38;5;66;03m#var_method=\"ls\")\u001b[39;00m\n\u001b[1;32m     14\u001b[0m     est_top_K \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39margsort(np\u001b[38;5;241m.\u001b[39mabs(kshap_ests))[::\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m][:K]\n\u001b[1;32m     16\u001b[0m     has_same_top_K \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray_equal(true_top_K, est_top_K)\n",
      "File \u001b[0;32m~/Desktop/RankSHAP/kernelshap.py:275\u001b[0m, in \u001b[0;36mkernelshap\u001b[0;34m(model, X, xloc, K, n_perms_btwn_tests, n_samples_per_perm, mapping_dict, alpha, K_thru_rest, perm_test, n, var_method, n_init, unbiased, max_n_perms)\u001b[0m\n\u001b[1;32m    <a href='file:///Users/jeremygoldwasser/Desktop/RankSHAP/kernelshap.py?line=272'>273</a>\u001b[0m     first \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[1;32m    <a href='file:///Users/jeremygoldwasser/Desktop/RankSHAP/kernelshap.py?line=273'>274</a>\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> <a href='file:///Users/jeremygoldwasser/Desktop/RankSHAP/kernelshap.py?line=274'>275</a>\u001b[0m     coalitions_new, coalition_values_new, coalition_vars_new \u001b[39m=\u001b[39m compute_coalitions_values(model, X, xloc, \n\u001b[1;32m    <a href='file:///Users/jeremygoldwasser/Desktop/RankSHAP/kernelshap.py?line=275'>276</a>\u001b[0m                                                             n_perms_btwn_tests, n_samples_per_perm, \n\u001b[1;32m    <a href='file:///Users/jeremygoldwasser/Desktop/RankSHAP/kernelshap.py?line=276'>277</a>\u001b[0m                                                             mapping_dict)\n\u001b[1;32m    <a href='file:///Users/jeremygoldwasser/Desktop/RankSHAP/kernelshap.py?line=277'>278</a>\u001b[0m     coalitions \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mconcatenate((coalitions, coalitions_new))\n\u001b[1;32m    <a href='file:///Users/jeremygoldwasser/Desktop/RankSHAP/kernelshap.py?line=278'>279</a>\u001b[0m     coalition_values \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mconcatenate((coalition_values, coalition_values_new))\n",
      "File \u001b[0;32m~/Desktop/RankSHAP/kernelshap.py:24\u001b[0m, in \u001b[0;36mcompute_coalitions_values\u001b[0;34m(model, X, xloc, n_perms_btwn_tests, n_samples_per_perm, mapping_dict)\u001b[0m\n\u001b[1;32m     <a href='file:///Users/jeremygoldwasser/Desktop/RankSHAP/kernelshap.py?line=21'>22</a>\u001b[0m z \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mzeros(d)\n\u001b[1;32m     <a href='file:///Users/jeremygoldwasser/Desktop/RankSHAP/kernelshap.py?line=22'>23</a>\u001b[0m z[S] \u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[0;32m---> <a href='file:///Users/jeremygoldwasser/Desktop/RankSHAP/kernelshap.py?line=23'>24</a>\u001b[0m w_x_vals \u001b[39m=\u001b[39m coalitions_kshap(X, xloc, z, n_samples_per_perm, mapping_dict)\n\u001b[1;32m     <a href='file:///Users/jeremygoldwasser/Desktop/RankSHAP/kernelshap.py?line=25'>26</a>\u001b[0m count \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m     <a href='file:///Users/jeremygoldwasser/Desktop/RankSHAP/kernelshap.py?line=26'>27</a>\u001b[0m coalitions \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mappend(coalitions, z)\u001b[39m.\u001b[39mreshape((count, d))        \n",
      "File \u001b[0;32m~/Desktop/RankSHAP/kernelshap.py:51\u001b[0m, in \u001b[0;36mcoalitions_kshap\u001b[0;34m(X, xloc, z, n_samples_per_perm, mapping_dict)\u001b[0m\n\u001b[1;32m     <a href='file:///Users/jeremygoldwasser/Desktop/RankSHAP/kernelshap.py?line=48'>49</a>\u001b[0m w_x_vals \u001b[39m=\u001b[39m []\n\u001b[1;32m     <a href='file:///Users/jeremygoldwasser/Desktop/RankSHAP/kernelshap.py?line=49'>50</a>\u001b[0m \u001b[39mfor\u001b[39;00m _ \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(n_samples_per_perm):\n\u001b[0;32m---> <a href='file:///Users/jeremygoldwasser/Desktop/RankSHAP/kernelshap.py?line=50'>51</a>\u001b[0m     w \u001b[39m=\u001b[39m X[np\u001b[39m.\u001b[39;49mrandom\u001b[39m.\u001b[39;49mchoice(X\u001b[39m.\u001b[39;49mshape[\u001b[39m0\u001b[39;49m], size\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m),:]\n\u001b[1;32m     <a href='file:///Users/jeremygoldwasser/Desktop/RankSHAP/kernelshap.py?line=51'>52</a>\u001b[0m     \u001b[39m# Copy xloc, then replace its \"unknown\" features with those of random sample w\u001b[39;00m\n\u001b[1;32m     <a href='file:///Users/jeremygoldwasser/Desktop/RankSHAP/kernelshap.py?line=52'>53</a>\u001b[0m     w_x_s \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mcopy(xloc)\n",
      "File \u001b[0;32mmtrand.pyx:946\u001b[0m, in \u001b[0;36mnumpy.random.mtrand.RandomState.choice\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m<__array_function__ internals>:177\u001b[0m, in \u001b[0;36mprod\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "%run kernelshap\n",
    "np.random.seed(1)\n",
    "K = 1\n",
    "true_order = get_ordering(true_shap_vals)\n",
    "true_top_K = true_order[:K]\n",
    "print(true_top_K)\n",
    "print(\"#\"*20)\n",
    "same_top_K = []\n",
    "for i in range(50):\n",
    "    print(i)\n",
    "    kshap_ests, kshap_vars, n_subsets = kernelshap(approx, X_train, xloc, K, \n",
    "            n_perms_btwn_tests=500, n_samples_per_perm=10, alpha=0.2, n_init=500, #n=50,\n",
    "            mapping_dict=mapping_dict, max_n_perms=10000, unbiased=True)#var_method=\"ls\")\n",
    "    est_top_K = np.argsort(np.abs(kshap_ests))[::-1][:K]\n",
    "\n",
    "    has_same_top_K = np.array_equal(true_top_K, est_top_K)\n",
    "    same_top_K.append(has_same_top_K)\n",
    "    if (i+1) % 5==0: print(est_top_K, n_subsets, 1-np.mean(same_top_K), i+1)\n",
    "    \n",
    "1-np.mean(same_top_K)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Unbiased KernelSHAP doesn't work\n",
    "I don't think there's a bug?\n",
    "- Running for 50k perms: Usually gets top 5 right, but they're out of order.\n",
    "- Generally, yeah, much more variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[8 3 2]\n",
      "Reached max number of permutations.\n",
      "[5 3 8]\n",
      "[ 5  3  8  2  7  4  9  1  0 10  6 11]\n",
      "[ 8  3  2  4  7  0 10 11  5  9  6  1]\n",
      "50000\n"
     ]
    }
   ],
   "source": [
    "%run kernelshap\n",
    "true_top_K = get_ordering(true_shap_vals)[:K]\n",
    "print(true_top_K)\n",
    "\n",
    "kshap_ests, kshap_vars, n_subsets = kernelshap(approx, X_train, xloc, K,\n",
    "        n_perms_btwn_tests=500, n_samples_per_perm=20,\n",
    "        mapping_dict=mapping_dict, alpha=0.2, n_init=500, unbiased=True,\n",
    "        perm_test=False, max_n_perms=50000)\n",
    "est_top_K = get_ordering(kshap_ests)[:K]\n",
    "print(est_top_K)\n",
    "\n",
    "print(get_ordering(kshap_ests))\n",
    "print(get_ordering(true_shap_vals))\n",
    "print(n_subsets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Weirdly, the permutation test says it converges when it obviously hasn't."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[8 3 2]\n",
      "[6 5 0]\n",
      "[ 6  5  0  3  4  8  7  2  9  1 10 11]\n",
      "[ 8  3  2  4  7  0 10 11  5  9  6  1]\n",
      "5000\n"
     ]
    }
   ],
   "source": [
    "kshap_ests, kshap_vars, n_subsets = kernelshap(approx, X_train, xloc, K,\n",
    "        n_perms_btwn_tests=500, n_samples_per_perm=20,\n",
    "        mapping_dict=mapping_dict, alpha=0.2, n_init=5000, unbiased=True,\n",
    "        perm_test=True, max_n_perms=50000)\n",
    "est_top_K = get_ordering(kshap_ests)[:K]\n",
    "print(true_top_K)\n",
    "print(est_top_K)\n",
    "\n",
    "print(get_ordering(kshap_ests))\n",
    "print(get_ordering(true_shap_vals))\n",
    "print(n_subsets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run many times on NN \n",
    "\n",
    "K=1: 20 perms btwn tests: FWER 16%\n",
    "- Higher number --> FWER goes to 0\n",
    "\n",
    "K=2: 20 perms btwn tests: FWER 16%\n",
    "K=3: gets stuck/ too slow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "here\n",
      "Reached max number of permutations.\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "5 0.4\n",
      "Reached max number of permutations.\n",
      "Reached max number of permutations.\n",
      "here\n",
      "here\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[38], line 9\u001b[0m\n\u001b[1;32m      6\u001b[0m ct \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m ct \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m50\u001b[39m:\n\u001b[1;32m      8\u001b[0m     \u001b[38;5;66;03m# print(i)\u001b[39;00m\n\u001b[0;32m----> 9\u001b[0m     kshap_ests, kshap_vars, n_subsets \u001b[38;5;241m=\u001b[39m \u001b[43mkernelshap\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mxloc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mK\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[43m            \u001b[49m\u001b[43mn_perms_btwn_tests\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m20\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_samples_per_perm\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m20\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[43m            \u001b[49m\u001b[43mmapping_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmapping_dict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[43mvar_method\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mboot\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;66;43;03m#n=20,\u001b[39;49;00m\n\u001b[1;32m     12\u001b[0m \u001b[43m            \u001b[49m\u001b[43malpha\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_init\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m200\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_n_perms\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_n_perms\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     13\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m n_subsets \u001b[38;5;241m<\u001b[39m max_n_perms:\n\u001b[1;32m     14\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhere\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/Desktop/RankSHAP/kernelshap.py:288\u001b[0m, in \u001b[0;36mkernelshap\u001b[0;34m(model, X, xloc, K, n_perms_btwn_tests, n_samples_per_perm, mapping_dict, alpha, K_thru_rest, perm_test, n, var_method, n_init, unbiased, max_n_perms)\u001b[0m\n\u001b[1;32m    <a href='file:///Users/jeremygoldwasser/Desktop/RankSHAP/kernelshap.py?line=285'>286</a>\u001b[0m         kshap_vars \u001b[39m=\u001b[39m compute_kshap_vars_ls(coalition_vars, coalitions)\n\u001b[1;32m    <a href='file:///Users/jeremygoldwasser/Desktop/RankSHAP/kernelshap.py?line=286'>287</a>\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> <a href='file:///Users/jeremygoldwasser/Desktop/RankSHAP/kernelshap.py?line=287'>288</a>\u001b[0m         kshap_vars \u001b[39m=\u001b[39m compute_kshap_vars_boot(y_pred, avg_pred, coalitions, \n\u001b[1;32m    <a href='file:///Users/jeremygoldwasser/Desktop/RankSHAP/kernelshap.py?line=288'>289</a>\u001b[0m                 coalition_values, n_boot\u001b[39m=\u001b[39;49m\u001b[39m250\u001b[39;49m)\n\u001b[1;32m    <a href='file:///Users/jeremygoldwasser/Desktop/RankSHAP/kernelshap.py?line=289'>290</a>\u001b[0m n_test \u001b[39m=\u001b[39m coalition_values\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m] \u001b[39mif\u001b[39;00m n \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m n\n\u001b[1;32m    <a href='file:///Users/jeremygoldwasser/Desktop/RankSHAP/kernelshap.py?line=290'>291</a>\u001b[0m converged \u001b[39m=\u001b[39m do_all_tests_pass_kshap(kshap_ests, kshap_vars, K, n\u001b[39m=\u001b[39mn_test,\n\u001b[1;32m    <a href='file:///Users/jeremygoldwasser/Desktop/RankSHAP/kernelshap.py?line=291'>292</a>\u001b[0m                                     alpha\u001b[39m=\u001b[39malpha, K_thru_rest\u001b[39m=\u001b[39mK_thru_rest, perm_test\u001b[39m=\u001b[39mperm_test)\n",
      "File \u001b[0;32m~/Desktop/RankSHAP/kernelshap.py:130\u001b[0m, in \u001b[0;36mcompute_kshap_vars_boot\u001b[0;34m(y_pred, avg_pred, coalitions, coalition_values, n_boot)\u001b[0m\n\u001b[1;32m    <a href='file:///Users/jeremygoldwasser/Desktop/RankSHAP/kernelshap.py?line=127'>128</a>\u001b[0m     coalition_values_boot \u001b[39m=\u001b[39m coalition_values[idx]\n\u001b[1;32m    <a href='file:///Users/jeremygoldwasser/Desktop/RankSHAP/kernelshap.py?line=128'>129</a>\u001b[0m     \u001b[39m# compute the kernelSHAP estimates on these bootstrapped samples, fitting ls\u001b[39;00m\n\u001b[0;32m--> <a href='file:///Users/jeremygoldwasser/Desktop/RankSHAP/kernelshap.py?line=129'>130</a>\u001b[0m     kshap_boot_all\u001b[39m.\u001b[39mappend(kshap_equation(y_pred, z_boot, coalition_values_boot, avg_pred))\n\u001b[1;32m    <a href='file:///Users/jeremygoldwasser/Desktop/RankSHAP/kernelshap.py?line=131'>132</a>\u001b[0m kshap_boot \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mstack(kshap_boot_all, axis\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m)\n\u001b[1;32m    <a href='file:///Users/jeremygoldwasser/Desktop/RankSHAP/kernelshap.py?line=132'>133</a>\u001b[0m kshap_vars_boot \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mcov(np\u001b[39m.\u001b[39marray(kshap_boot), rowvar\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n",
      "File \u001b[0;32m~/Desktop/RankSHAP/kernelshap.py:95\u001b[0m, in \u001b[0;36mkshap_equation\u001b[0;34m(yloc, coalitions, coalition_values, avg_pred, unbiased)\u001b[0m\n\u001b[1;32m     <a href='file:///Users/jeremygoldwasser/Desktop/RankSHAP/kernelshap.py?line=92'>93</a>\u001b[0m \u001b[39m# Compute v(1), the prediction made using all known features in xloc\u001b[39;00m\n\u001b[1;32m     <a href='file:///Users/jeremygoldwasser/Desktop/RankSHAP/kernelshap.py?line=93'>94</a>\u001b[0m M, d \u001b[39m=\u001b[39m coalitions\u001b[39m.\u001b[39mshape \u001b[39m# d low-dim if mapped\u001b[39;00m\n\u001b[0;32m---> <a href='file:///Users/jeremygoldwasser/Desktop/RankSHAP/kernelshap.py?line=94'>95</a>\u001b[0m avg_pred_vec \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39;49mrepeat(avg_pred, M)\n\u001b[1;32m     <a href='file:///Users/jeremygoldwasser/Desktop/RankSHAP/kernelshap.py?line=96'>97</a>\u001b[0m \u001b[39m# A matrix and b vector in Covert and Lee\u001b[39;00m\n\u001b[1;32m     <a href='file:///Users/jeremygoldwasser/Desktop/RankSHAP/kernelshap.py?line=97'>98</a>\u001b[0m \u001b[39mif\u001b[39;00m unbiased:\n",
      "File \u001b[0;32m<__array_function__ internals>:180\u001b[0m, in \u001b[0;36mrepeat\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/shap/lib/python3.9/site-packages/numpy/core/fromnumeric.py:479\u001b[0m, in \u001b[0;36mrepeat\u001b[0;34m(a, repeats, axis)\u001b[0m\n\u001b[1;32m    <a href='file:///Users/jeremygoldwasser/opt/anaconda3/envs/shap/lib/python3.9/site-packages/numpy/core/fromnumeric.py?line=435'>436</a>\u001b[0m \u001b[39m@array_function_dispatch\u001b[39m(_repeat_dispatcher)\n\u001b[1;32m    <a href='file:///Users/jeremygoldwasser/opt/anaconda3/envs/shap/lib/python3.9/site-packages/numpy/core/fromnumeric.py?line=436'>437</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mrepeat\u001b[39m(a, repeats, axis\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[1;32m    <a href='file:///Users/jeremygoldwasser/opt/anaconda3/envs/shap/lib/python3.9/site-packages/numpy/core/fromnumeric.py?line=437'>438</a>\u001b[0m     \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    <a href='file:///Users/jeremygoldwasser/opt/anaconda3/envs/shap/lib/python3.9/site-packages/numpy/core/fromnumeric.py?line=438'>439</a>\u001b[0m \u001b[39m    Repeat elements of an array.\u001b[39;00m\n\u001b[1;32m    <a href='file:///Users/jeremygoldwasser/opt/anaconda3/envs/shap/lib/python3.9/site-packages/numpy/core/fromnumeric.py?line=439'>440</a>\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    <a href='file:///Users/jeremygoldwasser/opt/anaconda3/envs/shap/lib/python3.9/site-packages/numpy/core/fromnumeric.py?line=476'>477</a>\u001b[0m \n\u001b[1;32m    <a href='file:///Users/jeremygoldwasser/opt/anaconda3/envs/shap/lib/python3.9/site-packages/numpy/core/fromnumeric.py?line=477'>478</a>\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> <a href='file:///Users/jeremygoldwasser/opt/anaconda3/envs/shap/lib/python3.9/site-packages/numpy/core/fromnumeric.py?line=478'>479</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m _wrapfunc(a, \u001b[39m'\u001b[39;49m\u001b[39mrepeat\u001b[39;49m\u001b[39m'\u001b[39;49m, repeats, axis\u001b[39m=\u001b[39;49maxis)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/shap/lib/python3.9/site-packages/numpy/core/fromnumeric.py:57\u001b[0m, in \u001b[0;36m_wrapfunc\u001b[0;34m(obj, method, *args, **kwds)\u001b[0m\n\u001b[1;32m     <a href='file:///Users/jeremygoldwasser/opt/anaconda3/envs/shap/lib/python3.9/site-packages/numpy/core/fromnumeric.py?line=53'>54</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m _wrapit(obj, method, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds)\n\u001b[1;32m     <a href='file:///Users/jeremygoldwasser/opt/anaconda3/envs/shap/lib/python3.9/site-packages/numpy/core/fromnumeric.py?line=55'>56</a>\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> <a href='file:///Users/jeremygoldwasser/opt/anaconda3/envs/shap/lib/python3.9/site-packages/numpy/core/fromnumeric.py?line=56'>57</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m bound(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n\u001b[1;32m     <a href='file:///Users/jeremygoldwasser/opt/anaconda3/envs/shap/lib/python3.9/site-packages/numpy/core/fromnumeric.py?line=57'>58</a>\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mTypeError\u001b[39;00m:\n\u001b[1;32m     <a href='file:///Users/jeremygoldwasser/opt/anaconda3/envs/shap/lib/python3.9/site-packages/numpy/core/fromnumeric.py?line=58'>59</a>\u001b[0m     \u001b[39m# A TypeError occurs if the object does have such a method in its\u001b[39;00m\n\u001b[1;32m     <a href='file:///Users/jeremygoldwasser/opt/anaconda3/envs/shap/lib/python3.9/site-packages/numpy/core/fromnumeric.py?line=59'>60</a>\u001b[0m     \u001b[39m# class, but its signature is not identical to that of NumPy's. This\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     <a href='file:///Users/jeremygoldwasser/opt/anaconda3/envs/shap/lib/python3.9/site-packages/numpy/core/fromnumeric.py?line=63'>64</a>\u001b[0m     \u001b[39m# Call _wrapit from within the except clause to ensure a potential\u001b[39;00m\n\u001b[1;32m     <a href='file:///Users/jeremygoldwasser/opt/anaconda3/envs/shap/lib/python3.9/site-packages/numpy/core/fromnumeric.py?line=64'>65</a>\u001b[0m     \u001b[39m# exception has a traceback chain.\u001b[39;00m\n\u001b[1;32m     <a href='file:///Users/jeremygoldwasser/opt/anaconda3/envs/shap/lib/python3.9/site-packages/numpy/core/fromnumeric.py?line=65'>66</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m _wrapit(obj, method, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# np.random.seed(2)\n",
    "K = 1\n",
    "top_K2_list = []\n",
    "max_n_perms = 2000\n",
    "# for i in range(50):\n",
    "ct = 0\n",
    "while ct < 50:\n",
    "    # print(i)\n",
    "    kshap_ests, kshap_vars, n_subsets = kernelshap(fmodel, X_train, xloc, K,\n",
    "            n_perms_btwn_tests=20, n_samples_per_perm=20,\n",
    "            mapping_dict=mapping_dict,  var_method=\"boot\",#n=20,\n",
    "            alpha=0.2, n_init=200, max_n_perms=max_n_perms)\n",
    "    if n_subsets < max_n_perms:\n",
    "        # print(\"here\")\n",
    "        est_top_K = get_ordering(kshap_ests)[:K]\n",
    "        top_K2_list.append(est_top_K)\n",
    "        ct += 1\n",
    "        if ct % 5==0: #print(ct)\n",
    "            top_K2 = np.array(top_K2_list)\n",
    "            most_common_row = mode_rows(top_K2)\n",
    "            ct2 = 0\n",
    "            for i in range(top_K2.shape[0]):\n",
    "                if np.array_equal(most_common_row, top_K2[i]):\n",
    "                    ct2 += 1\n",
    "            print(ct, np.round(1 - ct2 / top_K2.shape[0], 2)) # FWER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "768407c71a286f507fab4bce553d71b5cbd766c247b76eb598ef769225202bc3"
  },
  "kernelspec": {
   "display_name": "Python 3.9.16 ('shap')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
